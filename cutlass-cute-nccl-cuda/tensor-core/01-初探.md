



![Alt text](image-tensor-core-1.png)


*  Volta Tensor Core
第一代Tensor Core支持FP16和FP32下的混合精度矩阵乘法，可提供每秒超过100万亿次（TFLOPS）的深度学习性能，是Pascal架构的5倍以上。

* Turing Tensor Core
第二代Tensor Core提供了一系列用于深度学习训练和推理的精度（从FP32到FP16再到INT8和INT4），每秒可提供高达500万亿次的张量运算。

* Ampere Tensor Core
第三代Tensor Core采用全新精度标准Tensor Float 32（TF32）与64位浮点（FP64），以加速并简化人工智能应用，可将人工智能速度提升至最高20倍。

* Hopper Tensor Core
第四代Tensor Core使用新的8位浮点精度（FP8），可为万亿参数模型训练提供比FP16高6倍的性能。FP8用于 Transformer引擎，能够应用FP8和FP16的混合精度模式，大幅加速Transformer训练，同时兼顾准确性。FP8还可大幅提升大型语言模型推理的速度，性能较Ampere提升高达30倍。

## 调用

除了使用CUDA生态库里的API调用Tensor Core，如cublas、cudnn等，Nvidia还提供了以下几种方式调用Tensor Core。

###  WMMA (Warp-level Matrix Multiply Accumulate) API

```
template<typename Use, int m, int n, int k, typename T, typename Layout=void> class fragment;

void load_matrix_sync(fragment<...> &a, const T* mptr, unsigned ldm);
void load_matrix_sync(fragment<...> &a, const T* mptr, unsigned ldm, layout_t layout);
void store_matrix_sync(T* mptr, const fragment<...> &a, unsigned ldm, layout_t layout);
void fill_fragment(fragment<...> &a, const T& v);
void mma_sync(fragment<...> &d, const fragment<...> &a, const fragment<...> &b, const fragment<...> &c, bool satf=false);
```
1. fragment：Tensor Core数据存储类，支持matrix_a、matrix_b和accumulator
2. load_matrix_sync：Tensor Core数据加载API，支持将矩阵数据从global memory或shared memory加载到fragment
3. store_matrix_sync：Tensor Core结果存储API，支持将计算结果从fragment存储到global memory或shared memory
4. fill_fragment：fragment填充API，支持常数值填充
5. mma_sync：Tensor Core矩阵乘计算API，支持D = AB + C或者C = AB + C
