
## vllm

![Alt text](img/cmu-11868-5/image-1.png)

### PagedAttention
> KV cache is split into multiple blocks
> Each block contains key and value vector for a fixed number of tokens

![Alt text](img/cmu-11868-5/image-2.png)

* KV Cache Manager
> KV Blocks = OS Pages
> Logical KV Blocks = Virtual Pages
> Physical KV Blocks = Physical Pages
> Tokens = Bytes
> Requests = Processes

![Alt text](img/cmu-11868-5/image-3.png)

![Alt text](img/cmu-11868-5/image-4.png)


#### Decoding with PagedAttention and vLLM
![Alt text](img/cmu-11868-5/image-5.png)
![Alt text](img/cmu-11868-5/image-6.png)
![Alt text](img/cmu-11868-5/image-7.png)
![Alt text](img/cmu-11868-5/image-8.png)
![Alt text](img/cmu-11868-5/image-9.png)

#### Application to Other Decoding Scenarios
* Parallel Sampling
![Alt text](img/cmu-11868-5/image-10.png)
![Alt text](img/cmu-11868-5/image-11.png)
![Alt text](img/cmu-11868-5/image-12.png)
![Alt text](img/cmu-11868-5/image-13.png)
![Alt text](img/cmu-11868-5/image-14.png)

* Beam Search
![Alt text](img/cmu-11868-5/image-15.png)

* Shared Prefix
![Alt text](img/cmu-11868-5/image-16.png)

## JAX
> Compiling machine learning programs via high-level tracing




