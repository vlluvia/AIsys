
# LLM Serving

## Architectures for LLM Applications

![alt text](../img/cmu-11868-2/image-1.png)

### Data Preprocessing / Embedding


* Data Pipelines
> Include loaders, parsers, and preprocessing.

Databricks/Airflow/Unstructured


* Embedding Model

1. OpenAI:  Effective but cheap
2. Cohere: Focus more on embeddings
3. Hugging Face:  Open-source
4. Customer Embedding: e.g. BERT


* Vector Database
1. Pinecone： Fully clound-hosted
2. chroma：Local vector management
3. Faiss：by meta
4. Weaviate： Open-source


### Prompt Construction / Retrieval

1. LlamaIndex
2. LangChain4


### Prompt Execution / Inference

1. LLM APIs：Proprietary APIs、Open APIs、ChatGPT
2. LLM Hosting：General Could（E.g. AWS, GCP, and Azure）、Opinionated Cloud（E.g. Databricks, Anyscale, and Mosaic）
3. LLM Cache：o E.g. Redis, SQLite, and GPTCache
4. Validation：E.g. Guardrails, Rebuff, and Guidance
5. Logging：E.g. Weights&Biases, MLflow, and PromptLayer
6. App Hosting：Vercel、Steamship、Anyscale and Modal


### AI Agent
AutoGPTL 
![alt text](../img/cmu-11868-2/image-2.png)

## Frameworks for LLM Serving

![alt text](../img/cmu-11868-2/image-3.png)

### Triton“s”

* NVIDIA
1. Dynamic Batching
![alt text](../img/cmu-11868-2/image-4.png)

2. Triton + LightSeq / TensorRT-LLM
![alt text](../img/cmu-11868-2/image-5.png)

3. Triton + FasterTransformer 
![alt text](../img/cmu-11868-2/image-6.png)
![alt text](../img/cmu-11868-2/image-7.png)

* OpenAI


### Text Generation Inference

![alt text](../img/cmu-11868-2/image-8.png)
![alt text](../img/cmu-11868-2/image-9.png)


### OpenLLM

### MLC LLM

![alt text](../img/cmu-11868-2/image-10.png)

### LightLLM

![alt text](../img/cmu-11868-2/image-11.png)


